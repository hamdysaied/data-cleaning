project >>
https://www.kaggle.com/hamdysaied/wrangle-act/edit/run/57970855
 ........................................................................
 import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import requests
import json
from IPython.display import Image
twitter_a=pd.read_csv('../input/weratedogsdataset/twitter-archive-enhanced-2.csv')
url='https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv'
response=requests.get(url)
with open ('image-prediction.tsv',mode='wb')as file:
    file.write(response.content)
image_p=pd.read_csv('image-prediction.tsv',sep='\t')
list_tweet=[]
with open ('../input/weratedogsdataset/tweet-json')as file:
    for line in file:
        list_tweet.append(json.loads(line))
        
tweet_data=pd.DataFrame(list_tweet,columns=['id','retweet_count','favorite_count'])
twitter_a.head()
twitter_a.info()
twitter_a.describe()
twitter_a[twitter_a.duplicated()].count()
image_p.info()
image_p[image_p[['tweet_id','jpg_url']].duplicated()].count()
tweet_data
tweet_data.info()
tweet_data.describe()
tweet_data[tweet_data.duplicated()].count()
twitter_a_cleaning=twitter_a.copy()
image_p_cleaning=image_p.copy()
tweet_data_cleaning=tweet_data.copy()
cond=twitter_a_cleaning['rating_numerator']<10
col=twitter_a_cleaning[cond]
col_cleaning=col['rating_numerator']
col_cleaning=col_cleaning+10
twitter_a_cleaning.loc[cond,'rating_numerator']=col_cleaning
twitter_a_cleaning[twitter_a_cleaning['rating_numerator']<10]
twitter_a_cleaning['tweet_id']=twitter_a_cleaning['tweet_id'].astype(str)
twitter_a_cleaning['timestamp']=pd.to_datetime(twitter_a_cleaning['timestamp'])
twitter_a_cleaning.info()
twitter_a_cleaning=twitter_a_cleaning.drop(['in_reply_to_status_id','in_reply_to_user_id','retweeted_status_id',
                                            'retweeted_status_user_id','retweeted_status_timestamp'],axis=1)
twitter_a_cleaning.columns.value_counts()
twitter_a_cleaning=twitter_a_cleaning.dropna()
twitter_a_cleaning.expanded_urls.isnull().value_counts()
twitter_a_cleaning=twitter_a_cleaning.drop('rating_denominator',axis=1)
twitter_a_cleaning=twitter_a_cleaning.rename(columns={'rating_numerator':'rating_(over_10)'})
twitter_a_cleaning.columns.value_counts()
twitter_a_cleaning.name=twitter_a_cleaning.name.str.lower()
twitter_a_cleaning.name
twitter_a_cleaning=pd.melt(twitter_a_cleaning,id_vars=['tweet_id','timestamp','source','text','expanded_urls',
                                                       'rating_(over_10)','name'])
twitter_a_cleaning=twitter_a_cleaning.drop('variable',axis=1)
twitter_a_cleaning=twitter_a_cleaning.rename(columns={'value':'dog_stage'})
twitter_a_cleaning.sample(5)
index_arr=twitter_a_cleaning[twitter_a_cleaning['name']=='none'].index
twitter_a_cleaning=twitter_a_cleaning.drop(index_arr)
#testing
twitter_a_cleaning[twitter_a_cleaning['name']=='none']
index_arr=twitter_a_cleaning[twitter_a_cleaning['dog_stage']=='None'].index
twitter_a_cleaning=twitter_a_cleaning.drop(index_arr)
#testing
twitter_a_cleaning[twitter_a_cleaning['dog_stage']=='None']
twitter_a_cleaning=twitter_a_cleaning.drop_duplicates()
image_p_cleaning['tweet_id']=image_p_cleaning['tweet_id'].astype(str)
#test
image_p_cleaning.info()
false=(image_p_cleaning['p1_dog']==False )& (image_p_cleaning['p2_dog'] == False)&(image_p_cleaning['p3_dog'] == False)
false_index=image_p_cleaning[false].index
image_p_cleaning=image_p_cleaning.drop(false_index)
#test
image_p_cleaning[image_p_cleaning[(image_p_cleaning['p1_dog']==False )&
                                  (image_p_cleaning['p2_dog'] == False)&(image_p_cleaning['p3_dog'] == False)]].count()
tweet_data_cleaning['id']=tweet_data_cleaning['id'].astype(str)
#testing
tweet_data_cleaning.info()
tweet_data_cleaning=tweet_data_cleaning.rename(columns={'id':'tweet_id'})
#testing
tweet_data_cleaning.columns.value_counts()
the_final_data=pd.merge(twitter_a_cleaning,image_p_cleaning,on='tweet_id',how='left')
the_final_data=pd.merge(the_final_data,tweet_data_cleaning,on='tweet_id',how='left')
the_final_data.sample(5)
the_final_data.info()
the_final_data=the_final_data.dropna()
the_final_data['p1_dog']=the_final_data['p1_dog'].astype(bool)
the_final_data['p2_dog']=the_final_data['p2_dog'].astype(bool)
the_final_data['p3_dog']=the_final_data['p3_dog'].astype(bool)
the_final_data.info()
the_final_data.sample(5)
row_index=np.arange(1,172)
the_final_data.index=row_index
the_final_data.head()
the_final_data.tail()
x=the_final_data['dog_stage'].value_counts()
plt.pie(x,labels=['pupper','doggo','puppo','floofer'],shadow=True,explode=(.1,.2,.2,.3),autopct='%1.1f%%')
plt.show()
plt.scatter(the_final_data.retweet_count,the_final_data.favorite_count)
plt.show()
plt.scatter(the_final_data.favorite_count,the_final_data['rating_(over_10)'])
plt.show()
